{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建预训练的文件夹\n",
    "PRETRAIN_DIR = '../../user_data/pre_train_model'\n",
    "if not os.path.exists(PRETRAIN_DIR):\n",
    "    os.makedirs(PRETRAIN_DIR)\n",
    "print('已创建预训练文件夹')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(filename):\n",
    "    '''读取文本'''\n",
    "    with open(filename, encoding='gbk') as f:\n",
    "        content = f.readlines()\n",
    "    return ''.join([x.replace('\\n','||') for x in content])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预料准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../../data/train/txt/','../../data/test/txt/','../../data/sample_example/']\n",
    "corpus = []\n",
    "for path in paths:\n",
    "    filenames = os.listdir(path)\n",
    "    filenames = [x for x in filenames if 'txt' in x]\n",
    "    for filename in filenames:\n",
    "#         print(path + filename)\n",
    "        with open(path + filename,encoding='gbk') as f:\n",
    "            content = f.readlines()\n",
    "            content = ''.join(content).replace('\\n','||').split('||||')\n",
    "            corpus += content\n",
    "corpus = [x.replace('||','\\n') for x in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpora/book_review_bert.txt','w+') as f:\n",
    "    for line in corpus:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要在终端运行，notebook会报错\n",
    "`python3 preprocess.py\\\n",
    " --corpus_path  corpora/book_review_bert.txt\\\n",
    " --vocab_path  models/google_zh_vocab.txt\\\n",
    " --dataset_path  dataset.pt\\\n",
    " --processes_num 4 --target bert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /wangjin_fix_1/pre_model/pytorch_bert/chinese_roberta_wwm_large_ext_pytorch models/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python scripts/convert_bert_from_huggingface_to_uer.py\\\n",
    " --input_model_path models/chinese_roberta_wwm_large_ext_pytorch/pytorch_model.bin\\\n",
    " --layers_num 24 --target bert`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\r\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\r\n"
     ]
    }
   ],
   "source": [
    "! nohup python3 pretrain.py --dataset_path dataset.pt --vocab_path models/google_zh_vocab.txt\\\n",
    " --pretrained_model_path google_model.bin --config_path models/bert_large_config.json\\\n",
    " --output_model_path models/output_model.bin --world_size 1 --gpu_ranks 0\\\n",
    " --embedding word_pos_seg --encoder transformer --mask fully_visible --target bert\\\n",
    " --total_steps 5000 --save_checkpoint_steps 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir bert_large_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp models/chinese_roberta_wwm_large_ext_pytorch/config.json  bert_large_model/config.json\n",
    "! cp models/chinese_roberta_wwm_large_ext_pytorch/vocab.txt bert_large_model/vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python scripts/convert_bert_from_uer_to_huggingface.py --input_model_path models/output_model.bin-5000\\\n",
    " --output_model_path bert_large_model/pytorch_model.bin\\\n",
    " --layers_num 24\\\n",
    " --target bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  5 11:58:06 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    54W / 300W |   2764MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
